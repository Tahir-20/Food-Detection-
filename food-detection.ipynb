{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array\nprint(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:38.255678Z","iopub.execute_input":"2022-05-05T18:59:38.256621Z","iopub.status.idle":"2022-05-05T18:59:43.384363Z","shell.execute_reply.started":"2022-05-05T18:59:38.256498Z","shell.execute_reply":"2022-05-05T18:59:43.38284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a list with the Filepaths for Training and Testing:\ntrain_dir = Path('../input/fruit-and-vegetable-image-recognition/train')\ntrain_filepaths = list(train_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:43.385958Z","iopub.execute_input":"2022-05-05T18:59:43.386289Z","iopub.status.idle":"2022-05-05T18:59:44.826477Z","shell.execute_reply.started":"2022-05-05T18:59:43.386249Z","shell.execute_reply":"2022-05-05T18:59:44.825697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = Path('../input/fruit-and-vegetable-image-recognition/test')\ntest_filepaths = list(test_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:44.829555Z","iopub.execute_input":"2022-05-05T18:59:44.829756Z","iopub.status.idle":"2022-05-05T18:59:45.155861Z","shell.execute_reply.started":"2022-05-05T18:59:44.829732Z","shell.execute_reply":"2022-05-05T18:59:45.155035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dir = Path('../input/fruit-and-vegetable-image-recognition/validation')\nval_filepaths = list(test_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.157533Z","iopub.execute_input":"2022-05-05T18:59:45.157797Z","iopub.status.idle":"2022-05-05T18:59:45.197533Z","shell.execute_reply.started":"2022-05-05T18:59:45.157764Z","shell.execute_reply":"2022-05-05T18:59:45.196868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_processing(filepath):\n    \"\"\" Create a DataFrame with the Filepath and the Labels of the Pictures\"\"\"\n\n    labels = [str(filepath[i]).split(\"/\")[-2] \\\n              for i in range(len(filepath))]\n\n    filepath = pd.Series(filepath, name='Filepath').astype(str)\n    labels = pd.Series(labels, name='Label')\n\n    # Concatenate filepaths and labels\n    df = pd.concat([filepath, labels], axis=1)\n\n    # Shuffle the DataFrame and reset index\n    df = df.sample(frac=1).reset_index(drop = True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.19879Z","iopub.execute_input":"2022-05-05T18:59:45.199135Z","iopub.status.idle":"2022-05-05T18:59:45.206366Z","shell.execute_reply.started":"2022-05-05T18:59:45.199102Z","shell.execute_reply":"2022-05-05T18:59:45.205735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = image_processing(train_filepaths)\ntest_df = image_processing(test_filepaths)\nval_df = image_processing(val_filepaths)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.207622Z","iopub.execute_input":"2022-05-05T18:59:45.20804Z","iopub.status.idle":"2022-05-05T18:59:45.247923Z","shell.execute_reply.started":"2022-05-05T18:59:45.208006Z","shell.execute_reply":"2022-05-05T18:59:45.247319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('-- Training Set --\\n')\nprint(f'Number of Pictures: {train_df.shape[0]}\\n')\nprint(f'Number of Different Labels: {len(train_df.Label.unique())}\\n')\nprint(f'Labels: {train_df.Label.unique()}')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.249184Z","iopub.execute_input":"2022-05-05T18:59:45.249538Z","iopub.status.idle":"2022-05-05T18:59:45.264134Z","shell.execute_reply.started":"2022-05-05T18:59:45.249506Z","shell.execute_reply":"2022-05-05T18:59:45.263521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.266617Z","iopub.execute_input":"2022-05-05T18:59:45.269429Z","iopub.status.idle":"2022-05-05T18:59:45.288857Z","shell.execute_reply.started":"2022-05-05T18:59:45.269383Z","shell.execute_reply":"2022-05-05T18:59:45.288152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with one Label of each Category:\ndf_unique = train_df.copy().drop_duplicates(subset=[\"Label\"]).reset_index()\n\n# Display some pictures of the Dataset:\nfig, axes = plt.subplots(nrows=6, ncols=6, figsize=(8, 7),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_unique.Filepath[i]))\n    ax.set_title(df_unique.Label[i], fontsize = 12)\nplt.tight_layout(pad=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:45.292591Z","iopub.execute_input":"2022-05-05T18:59:45.294811Z","iopub.status.idle":"2022-05-05T18:59:53.438806Z","shell.execute_reply.started":"2022-05-05T18:59:45.294774Z","shell.execute_reply":"2022-05-05T18:59:53.438186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\ntest_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:53.441622Z","iopub.execute_input":"2022-05-05T18:59:53.441954Z","iopub.status.idle":"2022-05-05T18:59:53.447994Z","shell.execute_reply.started":"2022-05-05T18:59:53.441922Z","shell.execute_reply":"2022-05-05T18:59:53.447268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:53.44937Z","iopub.execute_input":"2022-05-05T18:59:53.449819Z","iopub.status.idle":"2022-05-05T18:59:54.609015Z","shell.execute_reply.started":"2022-05-05T18:59:53.449784Z","shell.execute_reply":"2022-05-05T18:59:54.608273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images = train_generator.flow_from_dataframe(\n    dataframe=val_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=True,\n    seed=0,\n    rotation_range=30,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:54.610118Z","iopub.execute_input":"2022-05-05T18:59:54.610535Z","iopub.status.idle":"2022-05-05T18:59:54.753895Z","shell.execute_reply.started":"2022-05-05T18:59:54.610497Z","shell.execute_reply":"2022-05-05T18:59:54.753205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=32,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:54.755068Z","iopub.execute_input":"2022-05-05T18:59:54.755291Z","iopub.status.idle":"2022-05-05T18:59:54.769939Z","shell.execute_reply.started":"2022-05-05T18:59:54.755261Z","shell.execute_reply":"2022-05-05T18:59:54.769114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:54.771712Z","iopub.execute_input":"2022-05-05T18:59:54.772341Z","iopub.status.idle":"2022-05-05T18:59:58.1592Z","shell.execute_reply.started":"2022-05-05T18:59:54.772306Z","shell.execute_reply":"2022-05-05T18:59:58.158334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\n\noutputs = tf.keras.layers.Dense(36, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    batch_size = 32,\n    epochs=5\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T18:59:58.160781Z","iopub.execute_input":"2022-05-05T18:59:58.161071Z","iopub.status.idle":"2022-05-05T19:11:12.221255Z","shell.execute_reply.started":"2022-05-05T18:59:58.161033Z","shell.execute_reply":"2022-05-05T19:11:12.220314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot()\nplt.title(\"Accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:12.222955Z","iopub.execute_input":"2022-05-05T19:11:12.223218Z","iopub.status.idle":"2022-05-05T19:11:12.444011Z","shell.execute_reply.started":"2022-05-05T19:11:12.22318Z","shell.execute_reply":"2022-05-05T19:11:12.443318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history)[['loss','val_loss']].plot()\nplt.title(\"Loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:12.445066Z","iopub.execute_input":"2022-05-05T19:11:12.445509Z","iopub.status.idle":"2022-05-05T19:11:12.660917Z","shell.execute_reply.started":"2022-05-05T19:11:12.445472Z","shell.execute_reply":"2022-05-05T19:11:12.660233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the Label of the test_images:\npred = model.predict(test_images)\npred = np.argmax(pred,axis=1)\n\n# Map the Label:\nlabels = (train_images.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\ny_test = [labels[k] for k in test_images.classes]","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:12.661953Z","iopub.execute_input":"2022-05-05T19:11:12.662323Z","iopub.status.idle":"2022-05-05T19:11:30.558997Z","shell.execute_reply.started":"2022-05-05T19:11:12.662288Z","shell.execute_reply":"2022-05-05T19:11:30.558263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, pred)\nprint(f'Accuracy on the test set: {100*acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:30.560153Z","iopub.execute_input":"2022-05-05T19:11:30.560758Z","iopub.status.idle":"2022-05-05T19:11:31.323513Z","shell.execute_reply.started":"2022-05-05T19:11:30.560717Z","shell.execute_reply":"2022-05-05T19:11:31.322738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y_test, pred, normalize='true')\nplt.figure(figsize = (15,10))\nsns.heatmap(cf_matrix, \n            annot=True, \n            xticklabels = sorted(set(y_test)), \n            yticklabels = sorted(set(y_test)),\n            )\nplt.title('Normalized Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:31.324837Z","iopub.execute_input":"2022-05-05T19:11:31.325244Z","iopub.status.idle":"2022-05-05T19:11:35.74612Z","shell.execute_reply.started":"2022-05-05T19:11:31.325207Z","shell.execute_reply":"2022-05-05T19:11:35.745423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(test_df.Filepath.iloc[i]))\n    ax.set_title(f\"True: {test_df.Label.iloc[i]}\\nPredicted: {pred[i]}\")\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:35.74739Z","iopub.execute_input":"2022-05-05T19:11:35.747782Z","iopub.status.idle":"2022-05-05T19:11:40.160597Z","shell.execute_reply.started":"2022-05-05T19:11:35.747743Z","shell.execute_reply":"2022-05-05T19:11:40.157816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output(location):\n    img=load_img(location,target_size=(224,224,3))\n    img=img_to_array(img)\n    img=img/255\n    img=np.expand_dims(img,[0])\n    answer=model.predict(img)\n    y_class = answer.argmax(axis=-1)\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = labels[y]\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:40.161843Z","iopub.execute_input":"2022-05-05T19:11:40.162127Z","iopub.status.idle":"2022-05-05T19:11:40.177615Z","shell.execute_reply.started":"2022-05-05T19:11:40.162086Z","shell.execute_reply":"2022-05-05T19:11:40.17684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = output('../input/fruit-and-vegetable-image-recognition/test/cabbage/Image_1.jpg')\nimg","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:40.178961Z","iopub.execute_input":"2022-05-05T19:11:40.179186Z","iopub.status.idle":"2022-05-05T19:11:41.562999Z","shell.execute_reply.started":"2022-05-05T19:11:40.179154Z","shell.execute_reply":"2022-05-05T19:11:41.562282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('FV.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:41.564517Z","iopub.execute_input":"2022-05-05T19:11:41.565538Z","iopub.status.idle":"2022-05-05T19:11:41.904668Z","shell.execute_reply.started":"2022-05-05T19:11:41.5655Z","shell.execute_reply":"2022-05-05T19:11:41.90394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install streamlit","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:41.908748Z","iopub.execute_input":"2022-05-05T19:11:41.909158Z","iopub.status.idle":"2022-05-05T19:11:54.435883Z","shell.execute_reply.started":"2022-05-05T19:11:41.909121Z","shell.execute_reply":"2022-05-05T19:11:54.434158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import streamlit as st\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img,img_to_array\nimport numpy as np\nfrom keras.models import load_model\nimport requests\nfrom bs4 import BeautifulSoup\n\nmodel = load_model('FV.h5')\nlabels = {0: 'apple', 1: 'banana', 2: 'beetroot', 3: 'bell pepper', 4: 'cabbage', 5: 'capsicum', 6: 'carrot', 7: 'cauliflower', 8: 'chilli pepper', 9: 'corn', 10: 'cucumber', 11: 'eggplant', 12: 'garlic', 13: 'ginger', 14: 'grapes', 15: 'jalepeno', 16: 'kiwi', 17: 'lemon', 18: 'lettuce',\n          19: 'mango', 20: 'onion', 21: 'orange', 22: 'paprika', 23: 'pear', 24: 'peas', 25: 'pineapple', 26: 'pomegranate', 27: 'potato', 28: 'raddish', 29: 'soy beans', 30: 'spinach', 31: 'sweetcorn', 32: 'sweetpotato', 33: 'tomato', 34: 'turnip', 35: 'watermelon'}\n\nfruits = ['Apple','Banana','Bello Pepper','Chilli Pepper','Grapes','Jalepeno','Kiwi','Lemon','Mango','Orange','Paprika','Pear','Pineapple','Pomegranate','Watermelon']\nvegetables = ['Beetroot','Cabbage','Capsicum','Carrot','Cauliflower','Corn','Cucumber','Eggplant','Ginger','Lettuce','Onion','Peas','Potato','Raddish','Soy Beans','Spinach','Sweetcorn','Sweetpotato','Tomato','Turnip']\n\ndef fetch_calories(prediction):\n    try:\n        url = 'https://www.google.com/search?&q=calories in ' + prediction\n        req = requests.get(url).text\n        scrap = BeautifulSoup(req, 'html.parser')\n        calories = scrap.find(\"div\", class_=\"BNeawe iBp4i AP7Wnd\").text\n        return calories\n    except Exception as e:\n        st.error(\"Can't able to fetch the Calories\")\n        print(e)\n\ndef processed_img(img_path):\n    img=load_img(img_path,target_size=(224,224,3))\n    img=img_to_array(img)\n    img=img/255\n    img=np.expand_dims(img,[0])\n    answer=model.predict(img)\n    y_class = answer.argmax(axis=-1)\n    print(y_class)\n    y = \" \".join(str(x) for x in y_class)\n    y = int(y)\n    res = labels[y]\n    print(res)\n    return res.capitalize()\n\ndef run():\n    st.title(\"Fruits-Vegetable Classification\")\n    img_file = st.file_uploader(\"Choose an Image\", type=[\"jpg\", \"png\"])\n    if img_file is not None:\n        img = Image.open(img_file).resize((250,250))\n        st.image(img,use_column_width=False)\n        save_image_path = './upload_images/'+img_file.name\n        with open(save_image_path, \"wb\") as f:\n            f.write(img_file.getbuffer())\n\n        # if st.button(\"Predict\"):\n        if img_file is not None:\n            result= processed_img(save_image_path)\n            print(result)\n            if result in vegetables:\n                st.info('**Category : Vegetables**')\n            else:\n                st.info('**Category : Fruit**')\n            st.success(\"**Predicted : \"+result+'**')\n            cal = fetch_calories(result)\n            if cal:\n                st.warning('**'+cal+'(100 grams)**')\nrun()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T19:11:54.437841Z","iopub.execute_input":"2022-05-05T19:11:54.438105Z","iopub.status.idle":"2022-05-05T19:11:56.469111Z","shell.execute_reply.started":"2022-05-05T19:11:54.438066Z","shell.execute_reply":"2022-05-05T19:11:56.468296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}